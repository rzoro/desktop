# -*- coding: utf-8 -*-
"""
Created on Tue Apr 17 11:26:23 2018

@author: drksu
"""

# titanic survival problem
# Look at training data and test data


# data analysis and wrangling

import pandas as pd
import numpy as np
import random as rnd

#for visualization

import seaborn as sns
import matplotlib.pyplot as plt

# machine learning
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import Perceptron
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier

print("importing is done")


#get data training and testing
#*
train_df = pd.read_csv('TitanicTrain.csv')
test_df = pd.read_csv('TitanicTest.csv')
#*
""" ANALYSIS STARTS
#Analyze by describing data
print(train_df.columns.values)

# look at first five records of read csv
print(train_df.head())
print('*'*20)
# look at last five records of read csv
print(train_df.tail())
"""
#preprocessing


#Combimning train and test data for analysis
combine = [train_df, test_df]

# analysing nature of columns ...attribuets..data
#Which features are categorical/numerical?
""" ANALYSIS STARTS
print(train_df.info())
print('_'*40)
print(test_df.info())



#know the statisticsl summary of attributes
# statastical chars of clomns of datasets- fundamental 

print(train_df.describe())
print('_'*40)
print(test_df.describe())

input('describing catagorical variables')
print('prining description of catagorical value')
print(train_df.describe(include=['O']))

#input('for name list descripbe')
names=pd.Series(['abc','def','ghi'])
print(names.describe())


# Top fives most common value in series
#frquency gives count of most commmonly used
#count gives no of Non Null values in that column

#input('output for name list descripbe')

#try to know correlation and identify information about data
"""

"""oBSERVATION sTARTS
Assumtions based on data analysis
We arrive at following assumptions based on data analysis done so far. We may validate these assumptions further before taking appropriate actions.

Correlating.

 to know how well does each feature correlate with Survival and wish to
 match these quick correlations with modelled correlations later.

Completing.

to complete Age feature as it is definitely correlated to survival.
to complete the Embarked feature as it may also correlate with survival or
another important feature.

Correcting.

Ticket feature may be dropped from our analysis as it contains high ratio of duplicates (22%) and
there may not be a correlation between Ticket and survival.

Cabin feature may be dropped as it is highly incomplete or
contains many null values both in training and test dataset.

PassengerId may be dropped from training dataset as it does not contribute to survival.

Name feature is relatively non-standard, may not contribute directly to survival, so maybe dropped.
Creating.

To create a new feature called Family based on Parch and SibSp
    to get total count of family members on board.
To engineer the Name feature to extract Title as a new feature.
To create new feature for Age bands. This turns a continous numerical feature into an ordinal categorical feature.
To create a Fare range feature if it helps our analysis.

Classifying.

Women (Sex=female) were more likely to have survived.
Children (Age<?) were more likely to have survived.
The upper-class passengers (Pclass=1) were more likely to have survived.

"""

"""Analysis Starts"""
"""
##correlation
print('-'*32)
print('relationship between Pclass and Survived')
print(train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))

# for Pclass =1 correlation is significant >0.5, Therefore must be used as a feature in classification


import numpy as np
print(np.corrcoef(train_df['Pclass'],train_df['Survived']))



print('-'*32)
print('relationship between Sex and Survived')
print(train_df[["Sex", "Survived"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))
# females have correlation > 0.5 so can be concluded that females are more probable to suivive than males

print('-'*32)
print('relationship between Sibsp and Survived')
print(train_df[["SibSp", "Survived"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))
#Sibsp is not having strong coorelation with survival.. but still can be correlated ,, Lets c
input('SibSp VS Survived')

print('-'*32)
print('relationship between parch and Survived')
print(train_df[["Parch", "Survived"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))
# parch also do not have strong correlation with survival except parch=3,1
#but still can be correlated
input('End of Correlation Analysis')
"""
#Analysis with Graphical views
# Graphical representation of Age and Surived
"""
g = sns.FacetGrid(train_df, col='Survived')
print(g.map(plt.hist, 'Age', bins=20))
plt.show()


Observations on AGE AND SURVIVAL
Infants (Age <=4) had high survival rate.
Oldest passengers (Age = 80) survived.
Large number of 15-25 year olds did not survive.
Most passengers are in 15-35 age range.
"""


# Mapping Pclass and AGE

grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)
grid.map(plt.hist, 'Age', alpha=.5, bins=20)
grid.add_legend()
plt.show()
input('Pclass and AGE vs Survived')
"""

"""
"""
Observation starts
Observations
Pclass=3 had most passengers, however most did not survive.
Infant passengers in Pclass=2 and Pclass=3 mostly survived. 
Most passengers in Pclass=1 survived. 
Pclass varies in terms of Age distribution of passengers.
"""

#GRAPHICAL ANALYSIS
#Correlating categorical features
print('corrlating Pclass, Survived, Sex and Embark')
grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)
grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')
grid.add_legend()
plt.show()
"""



#OBSERVATIONS
Female passengers had much better survival rate than males.
Exception in Embarked=C where males had higher survival rate.
This could be a correlation between Pclass and Embarked and in turn Pclass and Survived,
not necessarily direct correlation between Embarked and Survived.
Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports.
Ports of embarkation have varying survival rates for Pclass=3 and among male passengers.
"""

"""GRAPHICAL ANALYSIS
#Correlating categorical and numerical features
print('Correlating categorical and numerical features')
grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)
grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)
grid.add_legend()
plt.show()
"""


"""Observations
Higher fare paying passengers had better survival.
Port of embarkation correlates with survival rates
"""



""" HINTS
Correcting by dropping features
This is a good starting goal to execute.
By dropping features we are dealing with fewer data points.
Speeds up  and eases the analysis.

Based on our assumptions and decisions we want
to drop the Cabin  and Ticket features.

#correcting by fropping features
"""
#priting shapes
print( train_df.shape, test_df.shape)
print("Before", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)
input('printing shapes')
#DROPPING TICKET AND CABIN COLUMNS
train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)
test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)
combine = [train_df, test_df]
print("After", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)
# remember combin is list of train_df and test_df



#Creating new feature extracting from existing
# When we plot Title, Age, and Survived, we note the following observations.
# Most titles band Age groups accurately. For example: Master title has Age mean of 5 years.
# Survival among Title Age bands varies slightly.
# Certain titles mostly survived (Mme, Lady, Sir) or did not (Don, Rev, Jonkheer).
# Decision.
#We decide to retain the new Title feature for model training.
# A pattern with one group will return a DataFrame with one column if expand=True.
#A pattern with one group will return a Series if expand=False.

a=[1,2,3,4,56]
print(train_df.info())
for dataset in combine:
    #extracting titles as any string preceeding .
    dataset['Title'] = dataset.Name.str.extract('([A-Za-z]+)\.', expand=False)
    
    #set expand=True and See the the effect a complete data frame is created one title for each record
    #with expand=False Just a series with all possible Titles are created
    
#print(dataset['Title'])
    
print(pd.crosstab(train_df['Title'], train_df['Sex']))

# Title is coorelted to Sex survival and sex
#We can replace many titles with a more common name or classify them as Rare

for dataset in combine:
    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',	'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')
    print('After Replacing rare titles as Lady, Coutees,Capt,Col, Don, Dr Major etc by rare')
    input('After Replacing rare titles as Lady, Coutees,Capt,Col, Don, Dr Major etc by rare')
    print(pd.crosstab(train_df['Title'], train_df['Sex']))

# replacing Mlle,Ms, Mrs,Mme as Miss
    dataset['Title']=dataset['Title'].replace('Mlle','Miss')
    dataset['Title']=dataset['Title'].replace('Mrs','Miss')
    dataset['Title']=dataset['Title'].replace('Ms', 'Miss')
    dataset['Title']=dataset['Title'].replace('Mme','Miss')
    
#ANALYSIS OF TITLE AND SURVIVED
print(train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())

#converting catagorical parameter title into ordinal type
titleMapped={"Mr":1,"Miss":2,"Mrs":3,"Master":4,"Rare":5}

for dataset in combine:
    dataset['Title']=dataset['Title'].map(titleMapped)
    # SIMILARLY REPLACE BLANK FIELDS BY 0
    dataset['Title']=dataset['Title'].fillna(0)
"""
print(train_df.head())
print(test_df.head())
"""


"""
Drop the Name feature from training and testing datasets.
We also do not need the PassengerId feature in the training dataset.
"""
print(train_df.shape, test_df.shape)
train_df = train_df.drop(['Name', 'PassengerId'], axis=1)
test_df = test_df.drop(['Name'], axis=1)
print(train_df.shape, test_df.shape)
print('priting train and test after dropping name and passenger AND name from train and test DF')
print(train_df.head())
print(train_df.tail())
combine = [train_df, test_df]

#mapping sex catagorical to ordinal
#DEALING WITH MISSED TITLE IS DONE BY SETTING MISSING VALUE AS 0
#NEXT TARGET IS TO DEAL WITH MISSING VALUES FOR AGE

grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)
grid.map(plt.hist, 'Age', alpha=.5, bins=20)
grid.add_legend()


#UNderstand missing information about age
print(train_df.describe())
print(train_df.info())
# recall describe gives statastical summary whereas general information is given by info
#info specifies that age is missing parameter for 891-714 records

# missing age can be guessed by differenways

#way1 : to decide /predict/ find value of missing age
"""
    Step 1: find standard deviation and mean of age
    Step 2: Generate an age as randomly generated number in between std deviation and mean


# Way 2: BETTER WAY TO GUESS MISSING PARAMTERS BY USING CORRELETED PAARAMTERS

STEP 1: find correrelation amon  Age, gender,Pclass
Step 2: Guess Age values using median values for Age across sets of Pclass and Gender feature combinations.
        So, median Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, and so on...
Step 3: there are 2 genders Male and female (now converted as 0 or 1)
Step 4: Thereare three by two
"""


#Converting a categorical feature
for dataset in combine:
    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)
print('head of sex --gender of passanger')
print(train_df.head())


#Completing a numerical continuous feature
# age information need to be completed for 2 diff Sex values (Male / Female)
# and 3 class of Pclass variables(1,2,3)
guess_ages = np.zeros((2,3))
input('')
print(guess_ages)

#dataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)[source]
#Return object with labels on given axis omitted where alternately any or all
#of the data are missing
# omitting null value rows

#calculating mean/median age for each combination of age and Pclass
input('printing age median')
k=1
c=1
for dataset in combine:
    #calculate median for both train and test data both
    print('for combine  '+str(c+1))
    for i in range(0, 2):
        for j in range(0, 3):
           guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()
           #print(guess_df)
           age_guess = guess_df.median()
           print('printing ith median age   '+str(k)+"th   "+str(age_guess)+ " i "+str(i)+ "  j"+str(j))
           guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5
           print('printing  guess_age close to 0.5  '+str(k)+"th   "+str(guess_ages[i,j])+ " i "+str(i)+ "  j"+str(j))
           k=k+1
           # age_mean = guess_df.mean()
           # age_std = guess_df.std()
           # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)
           # Convert random age float to nearest .5 age
           guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5
        # Replace null age infromation by mediated Age
        
        for i in range(0, 2):
            for j in range(0, 3):
                dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\
                    'Age'] = guess_ages[i,j]

        dataset['Age'] = dataset['Age'].astype(int)
        print(train_df.head())

           
#  create Age bands and determine correlations with Survived.
#The cut function can be useful for going from a continuous variable to a
# categorical variable. For example, cut could convert ages to groups of age range

# cut automaticslly derives bins to fit age values in five bands
#If bins is an int, it defines the number of equal-width bins in the range of x.
#However, in this case, the range of x is extended by .1% on each side to include
#the min or max values of x. If bins is a sequence it defines the bin edges allowing
#for non-uniform bin width. No extension of the range of x is done in this case.

train_df['AgeBand'] = pd.cut(train_df['Age'], 5)
input('printing age bands and correctin ')
print(train_df['AgeBand'])

#Analyze correlation between Age and Surived

print(train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True))

#OBSERVATIONS:
# IN BAND 1 UPTO 16 YEARS  : SURVIVAL MEAN IS 59 I.E. SIGNIFICANT
# WHEREAS FOR LAST BAND    : FOR AGE > 64 ITS VERY VERY LESS APPRAOCHING TO 0

#Let us replace Age with ordinals based on these bands.
for dataset in combine:    
    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0
    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1
    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2
    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3
    dataset.loc[ dataset['Age'] > 64, 'Age']
print(train_df.head())

#Create new feature combining existing features
#We can create a new feature for FamilySize which combines Parch and SibSp.
#This will enable us to drop Parch and SibSp from our datasets.

for dataset in combine:
    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1

print(train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False))
"""
OBSERVATION
FAMILY SIZE AFFECTS SURVIVED PARAMETER
"""

#We can create another feature called IsAlone.
#i.e. If FAMILY SIZE IS 1 THEN PASSANGER IS ALONE AND OTHERWISE NOT ALONE

for dataset in combine:
    dataset['IsAlone'] = 0
    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1

print(train_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())

#Let us drop Parch, SibSp, and FamilySize features in favor of IsAlone.

train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)
test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)
combine = [train_df, test_df]

print(train_df.head())

#We can also create an artificial feature combining Pclass and Age.
for dataset in combine:
    dataset['Age*Class'] = dataset.Age * dataset.Pclass

print(train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10))

"""COMPLETING MISSING VALUE FOR CATAGORICAL FEATURE EMBARKED
Embarked feature takes S, Q, C values based on port of embarkation.
Our training dataset has two missing values. We simply fill these with
the most common occurance.
"""

#IDENTIFY MOST COMMON VALUE I.E MODE FOR EMBARKED COLUMN
freq_port = train_df.Embarked.dropna().mode()[0]
freq_port

#REPLACING MISSING VALUES WITH MOST COMMON VALUE
for dataset in combine:
    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)
    
#ANALYSIS OF EMBARKED PARAMETER ON SURVIVED
train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)


#Converting categorical feature to numeric EMBARKED TO NUMERIC VALUES 0,1,2 SO ON
for dataset in combine:
    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)
print(train_df.head())

#Quick completing and converting a numeric feature
test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)
test_df.head()

train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)
train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)


#Convert the Fare feature to ordinal values based on the FareBand
for dataset in combine:
    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0
    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1
    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2
    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3
    dataset['Fare'] = dataset['Fare'].astype(int)

train_df = train_df.drop(['FareBand'], axis=1)
combine = [train_df, test_df]
    
print(train_df.head(10))
print('Parameters finallly used for model constructions are PassengerId	Pclass	Sex	Age	Fare	Embarked	Title	IsAlone	Age*Class')
###################
##Model, predict and solve
#######


X_train = train_df.drop("Survived", axis=1)
Y_train = train_df["Survived"]
X_test  = test_df.drop("PassengerId", axis=1).copy()

print(X_train.shape, Y_train.shape, X_test.shape)

# Logistic Regression
"""
input('LR')
print(X_train)
logreg = LogisticRegression()
logreg.fit(X_train, Y_train)
Y_pred = logreg.predict(X_test)
acc_log = round(logreg.score(X_train, Y_train) * 100, 2)
print(acc_log)
"""
"""

Positive coefficients increase the log-odds of the response (and thus increase the probability),
and negative coefficients decrease the log-odds of the response (and thus decrease the probability).

Sex is highest positivie coefficient, implying as the Sex value increases (male: 0 to female: 1),
the probability of Survived=1 increases the most.
Inversely as Pclass increases, probability of Survived=1 decreases the most.
This way Age*Class is a good artificial feature to model as it has second highest negative
correlation with Survived.
So is Title as second highest positive correlation.
"""
coeff_df = pd.DataFrame(train_df.columns.delete(0))
coeff_df.columns = ['Feature']
#coeff_df["Correlation"] = pd.Series(logreg.coef_[0])
#actualy uncomment above n bellow line
#coeff_df.sort_values(by='Correlation', ascending=False)

#SVC
# Support Vector Machines
"""
svc = SVC()
svc.fit(X_train, Y_train)
Y_pred = svc.predict(X_test)
acc_svc = round(svc.score(X_train, Y_train) * 100, 2)
print(acc_svc)
"""
#KNN
"""
knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(X_train, Y_train)
Y_pred = knn.predict(X_test)
acc_knn = round(knn.score(X_train, Y_train) * 100, 2)
print(acc_knn)
"""
# Gaussian Naive Bayes
"""
gaussian = GaussianNB()
gaussian.fit(X_train, Y_train)
Y_pred = gaussian.predict(X_test)
acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)
print(acc_gaussian)
"""
# Perceptron
"""
perceptron = Perceptron()
perceptron.fit(X_train, Y_train)
Y_pred = perceptron.predict(X_test)
acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)
print(acc_perceptron)
"""
# Linear SVC
"""
linear_svc = LinearSVC()
linear_svc.fit(X_train, Y_train)
Y_pred = linear_svc.predict(X_test)
acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)
print(acc_linear_svc)
"""
# Stochastic Gradient Descent
"""
sgd = SGDClassifier()
sgd.fit(X_train, Y_train)
Y_pred = sgd.predict(X_test)
acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)
print(acc_sgd)
"""
# Decision Tree
"""
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, Y_train)
Y_pred = decision_tree.predict(X_test)
acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)
print(acc_decision_tree)
"""

# Random Forest
"""
random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(X_train, Y_train)
Y_pred = random_forest.predict(X_test)
random_forest.score(X_train, Y_train)
acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)
print(acc_random_forest)
"""
#Model evaluation
"""
models = pd.DataFrame({
    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 
              'Random Forest', 'Naive Bayes', 'Perceptron', 
              'Stochastic Gradient Decent', 'Linear SVC', 
              'Decision Tree'],
    'Score': [acc_svc, acc_knn, acc_log, 
              acc_random_forest, acc_gaussian, acc_perceptron, 
              acc_sgd, acc_linear_svc, acc_decision_tree]})
models.sort_values(by='Score', ascending=False)

submission = pd.DataFrame({
        "PassengerId": test_df["PassengerId"],
        "Survived": Y_pred
    })
"""

################################OUTPUT#########################################

runfile('C:/Users/drksu/Desktop/titanic/titanic.py', wdir='C:/Users/drksu/Desktop/titanic')
importing is done
 

Pclass and AGE vs Survived 
corrlating Pclass, Survived, Sex and Embark
C:\Users\drksu\Anaconda3\lib\site-packages\seaborn\axisgrid.py:703: UserWarning: Using the pointplot function without specifying `order` is likely to produce an incorrect plot.
  warnings.warn(warning)
C:\Users\drksu\Anaconda3\lib\site-packages\seaborn\axisgrid.py:708: UserWarning: Using the pointplot function without specifying `hue_order` is likely to produce an incorrect plot.
  warnings.warn(warning)
 

(891, 12) (418, 11)
Before (891, 12) (418, 11) (891, 12) (418, 11)

printing shapes 
After (891, 10) (418, 9) (891, 10) (418, 9)
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 10 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            714 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Fare           891 non-null float64
Embarked       889 non-null object
dtypes: float64(2), int64(5), object(3)
memory usage: 69.7+ KB
None
Sex       female  male
Title                 
Capt           0     1
Col            0     2
Countess       1     0
Don            0     1
Dr             1     6
Jonkheer       0     1
Lady           1     0
Major          0     2
Master         0    40
Miss         182     0
Mlle           2     0
Mme            1     0
Mr             0   517
Mrs          125     0
Ms             1     0
Rev            0     6
Sir            0     1
After Replacing rare titles as Lady, Coutees,Capt,Col, Don, Dr Major etc by rare

After Replacing rare titles as Lady, Coutees,Capt,Col, Don, Dr Major etc by rare 
Sex     female  male
Title               
Master       0    40
Miss       182     0
Mlle         2     0
Mme          1     0
Mr           0   517
Mrs        125     0
Ms           1     0
Rare         3    20
After Replacing rare titles as Lady, Coutees,Capt,Col, Don, Dr Major etc by rare

After Replacing rare titles as Lady, Coutees,Capt,Col, Don, Dr Major etc by rare 
Sex     female  male
Title               
Master       0    40
Miss       311     0
Mr           0   517
Rare         3    20
    Title  Survived
0  Master  0.575000
1    Miss  0.739550
2      Mr  0.156673
3    Rare  0.347826
(891, 11) (418, 10)
(891, 9) (418, 9)
priting train and test after dropping name and passenger AND name from train and test DF
   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Title
0         0       3    male  22.0      1      0   7.2500        S      1
1         1       1  female  38.0      1      0  71.2833        C      2
2         1       3  female  26.0      0      0   7.9250        S      2
3         1       1  female  35.0      1      0  53.1000        S      2
4         0       3    male  35.0      0      0   8.0500        S      1
     Survived  Pclass     Sex   Age  SibSp  Parch   Fare Embarked  Title
886         0       2    male  27.0      0      0  13.00        S      5
887         1       1  female  19.0      0      0  30.00        S      2
888         0       3  female   NaN      1      2  23.45        S      2
889         1       1    male  26.0      0      0  30.00        C      1
890         0       3    male  32.0      0      0   7.75        Q      1
         Survived      Pclass         Age       SibSp       Parch        Fare  \
count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000   
mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208   
std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429   
min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   
25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400   
50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200   
75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000   
max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   

            Title  
count  891.000000  
mean     1.586981  
std      0.906908  
min      1.000000  
25%      1.000000  
50%      1.000000  
75%      2.000000  
max      5.000000  
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 9 columns):
Survived    891 non-null int64
Pclass      891 non-null int64
Sex         891 non-null object
Age         714 non-null float64
SibSp       891 non-null int64
Parch       891 non-null int64
Fare        891 non-null float64
Embarked    889 non-null object
Title       891 non-null int64
dtypes: float64(2), int64(5), object(2)
memory usage: 62.7+ KB
None
head of sex --gender of passanger
   Survived  Pclass  Sex   Age  SibSp  Parch     Fare Embarked  Title
0         0       3    0  22.0      1      0   7.2500        S      1
1         1       1    1  38.0      1      0  71.2833        C      2
2         1       3    1  26.0      0      0   7.9250        S      2
3         1       1    1  35.0      1      0  53.1000        S      2
4         0       3    0  35.0      0      0   8.0500        S      1


[[0. 0. 0.]
 [0. 0. 0.]]

printing age median 
for combine  2
printing ith median age   1th   40.0 i 0  j0
printing  guess_age close to 0.5  1th   40.0 i 0  j0
printing ith median age   2th   30.0 i 0  j1
printing  guess_age close to 0.5  2th   30.0 i 0  j1
printing ith median age   3th   25.0 i 0  j2
printing  guess_age close to 0.5  3th   25.0 i 0  j2
   Survived  Pclass  Sex  Age  SibSp  Parch     Fare Embarked  Title
0         0       3    0   22      1      0   7.2500        S      1
1         1       1    1   38      1      0  71.2833        C      2
2         1       3    1   26      0      0   7.9250        S      2
3         1       1    1   35      1      0  53.1000        S      2
4         0       3    0   35      0      0   8.0500        S      1
printing ith median age   4th   32.5 i 1  j0
printing  guess_age close to 0.5  4th   32.5 i 1  j0
printing ith median age   5th   28.0 i 1  j1
printing  guess_age close to 0.5  5th   28.0 i 1  j1
printing ith median age   6th   15.5 i 1  j2
printing  guess_age close to 0.5  6th   15.5 i 1  j2
   Survived  Pclass  Sex  Age  SibSp  Parch     Fare Embarked  Title
0         0       3    0   22      1      0   7.2500        S      1
1         1       1    1   38      1      0  71.2833        C      2
2         1       3    1   26      0      0   7.9250        S      2
3         1       1    1   35      1      0  53.1000        S      2
4         0       3    0   35      0      0   8.0500        S      1
for combine  2
printing ith median age   7th   42.0 i 0  j0
printing  guess_age close to 0.5  7th   42.0 i 0  j0
printing ith median age   8th   28.0 i 0  j1
printing  guess_age close to 0.5  8th   28.0 i 0  j1
printing ith median age   9th   24.0 i 0  j2
printing  guess_age close to 0.5  9th   24.0 i 0  j2
   Survived  Pclass  Sex  Age  SibSp  Parch     Fare Embarked  Title
0         0       3    0   22      1      0   7.2500        S      1
1         1       1    1   38      1      0  71.2833        C      2
2         1       3    1   26      0      0   7.9250        S      2
3         1       1    1   35      1      0  53.1000        S      2
4         0       3    0   35      0      0   8.0500        S      1
printing ith median age   10th   39.0 i 1  j0
printing  guess_age close to 0.5  10th   39.0 i 1  j0
printing ith median age   11th   24.0 i 1  j1
printing  guess_age close to 0.5  11th   24.0 i 1  j1
printing ith median age   12th   18.0 i 1  j2
printing  guess_age close to 0.5  12th   18.0 i 1  j2
   Survived  Pclass  Sex  Age  SibSp  Parch     Fare Embarked  Title
0         0       3    0   22      1      0   7.2500        S      1
1         1       1    1   38      1      0  71.2833        C      2
2         1       3    1   26      0      0   7.9250        S      2
3         1       1    1   35      1      0  53.1000        S      2
4         0       3    0   35      0      0   8.0500        S      1

printing age bands and correctin 
0       (16.0, 32.0]
1       (32.0, 48.0]
2       (16.0, 32.0]
3       (32.0, 48.0]
4       (32.0, 48.0]
5       (16.0, 32.0]
6       (48.0, 64.0]
7      (-0.08, 16.0]
8       (16.0, 32.0]
9      (-0.08, 16.0]
10     (-0.08, 16.0]
11      (48.0, 64.0]
12      (16.0, 32.0]
13      (32.0, 48.0]
14     (-0.08, 16.0]
15      (48.0, 64.0]
16     (-0.08, 16.0]
17      (16.0, 32.0]
18      (16.0, 32.0]
19     (-0.08, 16.0]
20      (32.0, 48.0]
21      (32.0, 48.0]
22     (-0.08, 16.0]
23      (16.0, 32.0]
24     (-0.08, 16.0]
25      (32.0, 48.0]
26      (16.0, 32.0]
27      (16.0, 32.0]
28     (-0.08, 16.0]
29      (16.0, 32.0]
     
861     (16.0, 32.0]
862     (32.0, 48.0]
863    (-0.08, 16.0]
864     (16.0, 32.0]
865     (32.0, 48.0]
866     (16.0, 32.0]
867     (16.0, 32.0]
868     (16.0, 32.0]
869    (-0.08, 16.0]
870     (16.0, 32.0]
871     (32.0, 48.0]
872     (32.0, 48.0]
873     (32.0, 48.0]
874     (16.0, 32.0]
875    (-0.08, 16.0]
876     (16.0, 32.0]
877     (16.0, 32.0]
878     (16.0, 32.0]
879     (48.0, 64.0]
880     (16.0, 32.0]
881     (32.0, 48.0]
882     (16.0, 32.0]
883     (16.0, 32.0]
884     (16.0, 32.0]
885     (32.0, 48.0]
886     (16.0, 32.0]
887     (16.0, 32.0]
888    (-0.08, 16.0]
889     (16.0, 32.0]
890     (16.0, 32.0]
Name: AgeBand, Length: 891, dtype: category
Categories (5, interval[float64]): [(-0.08, 16.0] < (16.0, 32.0] < (32.0, 48.0] < (48.0, 64.0] < (64.0, 80.0]]
         AgeBand  Survived
0  (-0.08, 16.0]  0.594771
1   (16.0, 32.0]  0.310421
2   (32.0, 48.0]  0.386473
3   (48.0, 64.0]  0.434783
4   (64.0, 80.0]  0.090909
   Survived  Pclass  Sex  Age  SibSp  Parch     Fare Embarked  Title  \
0         0       3    0    1      1      0   7.2500        S      1   
1         1       1    1    2      1      0  71.2833        C      2   
2         1       3    1    1      0      0   7.9250        S      2   
3         1       1    1    2      1      0  53.1000        S      2   
4         0       3    0    2      0      0   8.0500        S      1   

        AgeBand  
0  (16.0, 32.0]  
1  (32.0, 48.0]  
2  (16.0, 32.0]  
3  (32.0, 48.0]  
4  (32.0, 48.0]  
   FamilySize  Survived
3           4  0.724138
2           3  0.578431
1           2  0.552795
6           7  0.333333
0           1  0.303538
4           5  0.200000
5           6  0.136364
7           8  0.000000
8          11  0.000000
   IsAlone  Survived
0        0  0.505650
1        1  0.303538
   Survived  Pclass  Sex  Age     Fare Embarked  Title       AgeBand  IsAlone
0         0       3    0    1   7.2500        S      1  (16.0, 32.0]        0
1         1       1    1    2  71.2833        C      2  (32.0, 48.0]        0
2         1       3    1    1   7.9250        S      2  (16.0, 32.0]        1
3         1       1    1    2  53.1000        S      2  (32.0, 48.0]        0
4         0       3    0    2   8.0500        S      1  (32.0, 48.0]        1
   Age*Class  Age  Pclass
0          3    1       3
1          2    2       1
2          3    1       3
3          2    2       1
4          6    2       3
5          3    1       3
6          3    3       1
7          0    0       3
8          3    1       3
9          0    0       2
   Survived  Pclass  Sex  Age     Fare  Embarked  Title       AgeBand  \
0         0       3    0    1   7.2500         0      1  (16.0, 32.0]   
1         1       1    1    2  71.2833         1      2  (32.0, 48.0]   
2         1       3    1    1   7.9250         0      2  (16.0, 32.0]   
3         1       1    1    2  53.1000         0      2  (32.0, 48.0]   
4         0       3    0    2   8.0500         0      1  (32.0, 48.0]   

   IsAlone  Age*Class  
0        0          3  
1        0          2  
2        1          3  
3        0          2  
4        1          6  
   Survived  Pclass  Sex  Age  Fare  Embarked  Title        AgeBand  IsAlone  \
0         0       3    0    1     0         0      1   (16.0, 32.0]        0   
1         1       1    1    2     3         1      2   (32.0, 48.0]        0   
2         1       3    1    1     1         0      2   (16.0, 32.0]        1   
3         1       1    1    2     3         0      2   (32.0, 48.0]        0   
4         0       3    0    2     1         0      1   (32.0, 48.0]        1   
5         0       3    0    1     1         2      1   (16.0, 32.0]        1   
6         0       1    0    3     3         0      1   (48.0, 64.0]        1   
7         0       3    0    0     2         0      4  (-0.08, 16.0]        0   
8         1       3    1    1     1         0      2   (16.0, 32.0]        0   
9         1       2    1    0     2         1      2  (-0.08, 16.0]        0   

   Age*Class  
0          3  
1          2  
2          3  
3          2  
4          6  
5          3  
6          3  
7          0  
8          3  
9          0  
Parameters finallly used for model constructions are PassengerId        Pclass  Sex     Age     Fare    Embarked        Title   IsAlone Age*Class
(891, 9) (891,) (418, 8)

 



